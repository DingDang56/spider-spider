2019-07-01 12:13:16 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: project)
2019-07-01 12:13:16 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.7.0, Python 3.6.3 |Anaconda, Inc.| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-7-6.1.7601-SP1
2019-07-01 12:13:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'project', 'LOG_FILE': 'meiju100.log', 'NEWSPIDER_MODULE': 'project.spiders', 'SPIDER_MODULES': ['project.spiders'], 'USER_AGENT': 'project (+http://www.yourdomain.com)'}
2019-07-01 12:13:16 [scrapy.extensions.telnet] INFO: Telnet Password: 27011def4b1bb061
2019-07-01 12:13:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-07-01 12:13:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-07-01 12:13:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-07-01 12:13:17 [scrapy.middleware] INFO: Enabled item pipelines:
['project.pipelines.ProjectPipeline']
2019-07-01 12:13:17 [scrapy.core.engine] INFO: Spider opened
2019-07-01 12:13:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-07-01 12:13:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-07-01 12:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.meijutt.com/new100.html> (referer: None)
2019-07-01 12:13:17 [scrapy.core.engine] INFO: Closing spider (finished)
2019-07-01 12:13:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 227,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6780,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 7, 1, 4, 13, 17, 620309),
 'log_count/DEBUG': 1,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 7, 1, 4, 13, 17, 120280)}
2019-07-01 12:13:17 [scrapy.core.engine] INFO: Spider closed (finished)
2019-07-01 12:17:00 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: project)
2019-07-01 12:17:00 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.7.0, Python 3.6.3 |Anaconda, Inc.| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-7-6.1.7601-SP1
2019-07-01 12:17:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'project', 'LOG_FILE': 'meiju100.log', 'NEWSPIDER_MODULE': 'project.spiders', 'SPIDER_MODULES': ['project.spiders'], 'USER_AGENT': 'project (+http://www.yourdomain.com)'}
2019-07-01 12:17:00 [scrapy.extensions.telnet] INFO: Telnet Password: 9aa7d9c403cb26df
2019-07-01 12:17:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-07-01 12:17:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-07-01 12:17:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-07-01 12:17:00 [scrapy.middleware] INFO: Enabled item pipelines:
['project.pipelines.ProjectPipeline']
2019-07-01 12:17:00 [scrapy.core.engine] INFO: Spider opened
2019-07-01 12:17:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-07-01 12:17:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-07-01 12:17:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.meijutt.com/new100.html> (referer: None)
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '1',
 'name': '落跑公主第一季',
 's_type': '喜剧,剧情',
 'state': '第5集',
 'tv': 'My-Lifetime',
 'u_time': '2019-7-1'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '2',
 'name': '私家侦探第三季',
 's_type': '罪案,动作,剧情',
 'state': '第6集',
 'tv': 'Global',
 'u_time': '2019-7-1'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '3',
 'name': '德州长子第二季',
 's_type': '西部,剧情',
 'state': '第10集',
 'tv': 'AMC',
 'u_time': '2019-7-1'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '4',
 'name': '女子无畏第三季',
 's_type': '剧情',
 'state': '本季终',
 'tv': 'FREEFORM',
 'u_time': '2019-7-1'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '5',
 'name': '三色堇第一季',
 's_type': '罪案,剧情',
 'state': '第12集',
 'tv': '其他',
 'u_time': '2019-7-1'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '6',
 'name': '碰撞第一季',
 's_type': '惊悚,动作,剧情',
 'state': '第20集',
 'tv': 'Show-TV',
 'u_time': '2019-7-1'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '7',
 'name': '奇幻沼泽第一季',
 's_type': '喜剧,动画,冒险',
 'state': '第8集',
 'tv': 'Disney',
 'u_time': '2019-7-1'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '8',
 'name': '边境第三季',
 's_type': '冒险',
 'state': '第2集',
 'tv': 'Netflix',
 'u_time': '2019-7-1'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '9',
 'name': '血疫第一季',
 's_type': '惊悚,剧情',
 'state': '本季终',
 'tv': 'National-Geographic-Channel',
 'u_time': '2019-7-1'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '10',
 'name': '诡媚海妖第二季',
 's_type': '奇幻,剧情',
 'state': '第12集',
 'tv': 'FREEFORM',
 'u_time': '2019-7-1'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '11',
 'name': '处女情缘第五季',
 's_type': '喜剧,剧情',
 'state': '第13集',
 'tv': 'CW',
 'u_time': '2019-6-30'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '12',
 'name': '魔女之家第二季',
 's_type': '情景喜剧',
 'state': '第2集',
 'tv': 'Disney',
 'u_time': '2019-6-30'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '13',
 'name': '小丑梦摇篮第四季',
 's_type': '喜剧,剧情',
 'state': '第3集',
 'tv': 'FX',
 'u_time': '2019-6-30'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '14',
 'name': '天佑吾王第一季',
 's_type': '剧情',
 'state': '第43集',
 'tv': '其他',
 'u_time': '2019-6-30'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '15',
 'name': '太空终界第二季',
 's_type': '科幻,动画',
 'state': '第1集',
 'tv': '其他',
 'u_time': '2019-6-30'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '16',
 'name': '周六夜现场第四十四季',
 's_type': '真人秀',
 'state': '第21集',
 'tv': 'NBC',
 'u_time': '2019-6-30'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '17',
 'name': '毒品第一季',
 's_type': '记录',
 'state': '本季终',
 'tv': 'Netflix',
 'u_time': '2019-6-30'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '18',
 'name': '女飞贼杰特第一季',
 's_type': '罪案,动作',
 'state': '第3集',
 'tv': 'Cinemax',
 'u_time': '2019-6-30'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '19',
 'name': '游戏玩家第一季',
 's_type': '罪案,悬疑,动作,剧情',
 'state': '第4集',
 'tv': '其他',
 'u_time': '2019-6-30'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '20',
 'name': '归去第一季',
 's_type': '惊悚,悬疑',
 'state': '第3集',
 'tv': '其他',
 'u_time': '2019-6-30'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '21',
 'name': '天选之子第一季',
 's_type': '惊悚,悬疑',
 'state': '第5集',
 'tv': 'Netflix',
 'u_time': '2019-6-30'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '22',
 'name': '无限恩典有限公司第一季',
 's_type': '剧情',
 'state': '第4集',
 'tv': 'EPIX',
 'u_time': '2019-6-29'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '23',
 'name': '沼泽怪物第一季',
 's_type': '惊悚,奇幻',
 'state': '第5集',
 'tv': 'DC-Universe',
 'u_time': '2019-6-29'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '24',
 'name': '为人师表第一季',
 's_type': '喜剧',
 'state': '本季终',
 'tv': 'Netflix',
 'u_time': '2019-6-29'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '25',
 'name': '复仇者集结第二季',
 's_type': '动画',
 'state': '本季终',
 'tv': 'Disney',
 'u_time': '2019-6-29'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '26',
 'name': '菜鸟警察第六季',
 's_type': '罪案,剧情',
 'state': '全剧完结',
 'tv': 'ABC',
 'u_time': '2019-6-29'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '27',
 'name': '神盾局特工第六季',
 's_type': '科幻,动作',
 'state': '第7集',
 'tv': 'ABC',
 'u_time': '2019-6-29'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '28',
 'name': '图塔卡门第一季',
 's_type': '迷你剧,历史,剧情',
 'state': '全剧完结',
 'tv': 'ITV',
 'u_time': '2019-6-29'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '29',
 'name': '音乐玩家第三季',
 's_type': '青春,喜剧',
 'state': '第11集',
 'tv': 'Disney-Channel',
 'u_time': '2019-6-29'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '30',
 'name': '我是僵尸第五季',
 's_type': '罪案,惊悚,剧情,丧尸',
 'state': '第9集',
 'tv': 'CW',
 'u_time': '2019-6-29'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '31',
 'name': '暗中第一季',
 's_type': '罪案,剧情',
 'state': '本季终',
 'tv': 'CW',
 'u_time': '2019-6-29'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '32',
 'name': '福尔摩斯：基本演绎法第七季',
 's_type': '罪案,悬疑,剧情',
 'state': '第6集',
 'tv': 'CBS',
 'u_time': '2019-6-29'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '33',
 'name': '戴上手套擦泪第一季',
 's_type': '爱情,同性,动作',
 'state': '第3集',
 'tv': '其他',
 'u_time': '2019-6-29'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '34',
 'name': '神秘天使第二季',
 's_type': '悬疑,剧情,传记',
 'state': '第3集',
 'tv': 'CBS',
 'u_time': '2019-6-28'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '35',
 'name': '暗礁第一季',
 's_type': '罪案,悬疑',
 'state': '第2集',
 'tv': 'ABC',
 'u_time': '2019-6-28'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '36',
 'name': '主厨秀第一季',
 's_type': '真人秀',
 'state': '第8集',
 'tv': '其他',
 'u_time': '2019-6-28'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '37',
 'name': '女作家与谋杀案第七季',
 's_type': '罪案,悬疑,剧情',
 'state': '第9集',
 'tv': '其他',
 'u_time': '2019-6-28'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '38',
 'name': '少年泰坦出击第五季',
 's_type': '动画',
 'state': '第38集',
 'tv': 'Cartoon-Network',
 'u_time': '2019-6-28'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '39',
 'name': '赎金第三季',
 's_type': '罪案,剧情',
 'state': '第5集',
 'tv': 'CBS',
 'u_time': '2019-6-28'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '40',
 'name': '德雷尔一家第四季',
 's_type': '爱情,喜剧,剧情,传记',
 'state': '第6集',
 'tv': 'ITV',
 'u_time': '2019-6-28'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '41',
 'name': '南方女王第四季',
 's_type': '罪案,惊悚,动作,剧情',
 'state': '第4集',
 'tv': 'USA-Network',
 'u_time': '2019-6-28'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '42',
 'name': '生活点滴第四季',
 's_type': '喜剧',
 'state': '全剧完结',
 'tv': 'CBS',
 'u_time': '2019-6-28'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '43',
 'name': '黑白恋曲第一季',
 's_type': '爱情,暴力',
 'state': '第12集',
 'tv': '其他',
 'u_time': '2019-6-28'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '44',
 'name': '野兽家族第四季',
 's_type': '罪案,剧情',
 'state': '第5集',
 'tv': 'TNT',
 'u_time': '2019-6-28'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '45',
 'name': '戴面纱的美人第一季',
 's_type': '爱情,家庭,剧情',
 'state': '第8集',
 'tv': 'RAI-1',
 'u_time': '2019-6-28'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '46',
 'name': '海湾之谜第一季',
 's_type': '剧情',
 'state': '本季终',
 'tv': 'ITV',
 'u_time': '2019-6-28'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '47',
 'name': '氪星第二季',
 's_type': '科幻,动作,剧情,冒险',
 'state': '第3集',
 'tv': 'Syfy',
 'u_time': '2019-6-27'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '48',
 'name': '黄石公园第二季',
 's_type': '西部,剧情',
 'state': '第2集',
 'tv': '其他',
 'u_time': '2019-6-27'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '49',
 'name': '年轻一代第六季',
 's_type': '爱情,喜剧',
 'state': '第3集',
 'tv': '其他',
 'u_time': '2019-6-27'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '50',
 'name': '白粉飞第二季',
 's_type': '罪案,剧情',
 'state': '第6集',
 'tv': '其他',
 'u_time': '2019-6-27'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '51',
 'name': '糟糕历史第六季',
 's_type': '家庭,喜剧,历史',
 'state': '第9集',
 'tv': 'BBC',
 'u_time': '2019-6-27'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '52',
 'name': '极速前进第三十一季',
 's_type': '真人秀',
 'state': '第11集',
 'tv': 'CBS',
 'u_time': '2019-6-27'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '53',
 'name': '厨艺大师第十季',
 's_type': '真人秀',
 'state': '第6集',
 'tv': 'FOX',
 'u_time': '2019-6-27'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '54',
 'name': '蔗糖女王第四季',
 's_type': '剧情',
 'state': '第3集',
 'tv': 'Oprah-Winfre',
 'u_time': '2019-6-27'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '55',
 'name': '成长不容易第二季',
 's_type': '喜剧',
 'state': '第15集',
 'tv': 'FREEFORM',
 'u_time': '2019-6-27'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '56',
 'name': '姿态第二季',
 's_type': '歌舞,历史,剧情',
 'state': '第3集',
 'tv': 'FX',
 'u_time': '2019-6-27'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '57',
 'name': '变形金刚：领袖之证第一季',
 's_type': '动画',
 'state': '第8集',
 'tv': 'The-Hub',
 'u_time': '2019-6-27'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '58',
 'name': '真我人生第二季',
 's_type': '剧情',
 'state': '本季终',
 'tv': 'Starz',
 'u_time': '2019-6-27'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '59',
 'name': '血宝藏第一季',
 's_type': '罪案,悬疑,冒险',
 'state': '第7集',
 'tv': 'CBS',
 'u_time': '2019-6-27'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '60',
 'name': '侍女的故事第三季',
 's_type': '科幻,剧情',
 'state': '第6集',
 'tv': 'Hulu',
 'u_time': '2019-6-27'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '61',
 'name': '地球百子第六季',
 's_type': '科幻,悬疑,剧情',
 'state': '第8集',
 'tv': 'CW',
 'u_time': '2019-6-27'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '62',
 'name': '麻烦一家人第二季',
 's_type': '爱情,喜剧,剧情',
 'state': '第2集',
 'tv': 'FREEFORM',
 'u_time': '2019-6-26'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '63',
 'name': '一路绕行第四季',
 's_type': '喜剧',
 'state': '第2集',
 'tv': 'TBS',
 'u_time': '2019-6-26'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '64',
 'name': '三人行第四季',
 's_type': '喜剧,剧情',
 'state': '第5集',
 'tv': '其他',
 'u_time': '2019-6-26'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '65',
 'name': '疯狂教授生物课第二季',
 's_type': '喜剧',
 'state': '第12集',
 'tv': 'NBC',
 'u_time': '2019-6-26'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '66',
 'name': '本能第二季',
 's_type': '罪案,剧情',
 'state': '预告',
 'tv': 'CBS',
 'u_time': '2019-6-26'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '67',
 'name': '行星第一季',
 's_type': '记录',
 'state': '本季终',
 'tv': 'BBC',
 'u_time': '2019-6-26'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '68',
 'name': '怪探拉比特第一季',
 's_type': '悬疑,喜剧',
 'state': '第3集',
 'tv': 'Channel 4',
 'u_time': '2019-6-26'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '69',
 'name': '比彻姆大宅第一季',
 's_type': '剧情',
 'state': '第2集',
 'tv': 'ITV',
 'u_time': '2019-6-26'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '70',
 'name': '追寻人生第二季',
 's_type': '都市,剧情',
 'state': '第8集',
 'tv': 'ABC-Family',
 'u_time': '2019-6-26'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '71',
 'name': '大群第三季',
 's_type': '科幻,动作,剧情',
 'state': '第1集',
 'tv': 'FX',
 'u_time': '2019-6-26'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '72',
 'name': '浮华饭店第一季',
 's_type': '剧情',
 'state': '第2集',
 'tv': '其他',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '73',
 'name': '死亡医生玛丽第三季',
 's_type': '罪案,医务,剧情',
 'state': '本季终',
 'tv': 'Lifetime',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '74',
 'name': '前哨第二季',
 's_type': '科幻,奇幻,冒险',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '75',
 'name': '大小谎言第二季',
 's_type': '罪案,喜剧,剧情',
 'state': '第3集',
 'tv': 'HBO',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '76',
 'name': '王冠第三季',
 's_type': '历史,剧情',
 'state': '预告',
 'tv': 'Netflix',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '77',
 'name': '女子监狱第七季',
 's_type': '罪案,喜剧,剧情',
 'state': '预告',
 'tv': 'Netflix',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '78',
 'name': '绿箭侠第八季',
 's_type': '罪案,科幻,动作',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '79',
 'name': '豪门恩怨第三季',
 's_type': '罪案,剧情',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '80',
 'name': '新圣女魔咒第二季',
 's_type': '奇幻,剧情',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '81',
 'name': '吸血鬼后裔第二季',
 's_type': '魔幻,悬疑,奇幻',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '82',
 'name': '河谷镇第四季',
 's_type': '惊悚,悬疑,剧情',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '83',
 'name': '神探南茜第一季',
 's_type': '罪案,惊悚,悬疑',
 'state': '预告',
 'tv': '其他',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '84',
 'name': '邪恶力量第十五季',
 's_type': '魔幻,惊悚,悬疑',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '85',
 'name': '闪电侠第六季',
 's_type': '科幻,动作,冒险',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '86',
 'name': '蝙蝠女侠第一季',
 's_type': '科幻,动作,冒险',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '87',
 'name': '女超人第五季',
 's_type': '科幻,动作,冒险',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '88',
 'name': '安迪・麦克第三季',
 's_type': '青春,剧情',
 'state': '第3集',
 'tv': 'Disney',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '89',
 'name': '亢奋第一季',
 's_type': '罪案,剧情',
 'state': '第2集',
 'tv': 'HBO',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '90',
 'name': '西班牙公主第一季',
 's_type': '历史,剧情',
 'state': '本季终',
 'tv': 'Starz',
 'u_time': '2019-6-25'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '91',
 'name': '洛城战警第一季',
 's_type': '罪案,喜剧,动作',
 'state': '第11集',
 'tv': '其他',
 'u_time': '2019-6-24'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '92',
 'name': '燃呀马德里第一季',
 's_type': '歌舞,喜剧',
 'state': '本季终',
 'tv': '其他',
 'u_time': '2019-6-24'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '93',
 'name': '神秘法医第二季',
 's_type': '罪案,医务',
 'state': '第7集',
 'tv': 'ABC',
 'u_time': '2019-6-24'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '94',
 'name': '行尸之惧第五季',
 's_type': '惊悚,丧尸',
 'state': '第4集',
 'tv': 'AMC',
 'u_time': '2019-6-24'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '95',
 'name': '认罪口供第一季',
 's_type': '记录,罪案',
 'state': '第4集',
 'tv': 'Netflix',
 'u_time': '2019-6-24'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '96',
 'name': '另一面第一季',
 's_type': '惊悚,历史,剧情',
 'state': '第10集',
 'tv': 'RTVE',
 'u_time': '2019-6-24'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '97',
 'name': '黑暗物质三部曲第一季',
 's_type': '魔幻,奇幻',
 'state': '预告',
 'tv': 'BBC',
 'u_time': '2019-6-24'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '98',
 'name': '以人民之名第二季',
 's_type': '剧情',
 'state': '第9集',
 'tv': 'ABC',
 'u_time': '2019-6-24'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '99',
 'name': '美爪屋第三季',
 's_type': '喜剧',
 'state': '第3集',
 'tv': 'TNT',
 'u_time': '2019-6-24'}
2019-07-01 12:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '100',
 'name': '山巅之城第一季',
 's_type': '罪案,惊悚,剧情',
 'state': '第2集',
 'tv': 'Showtime',
 'u_time': '2019-6-24'}
2019-07-01 12:17:01 [scrapy.core.engine] INFO: Closing spider (finished)
2019-07-01 12:17:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 227,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6780,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 7, 1, 4, 17, 1, 465112),
 'item_scraped_count': 100,
 'log_count/DEBUG': 101,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 7, 1, 4, 17, 0, 859077)}
2019-07-01 12:17:01 [scrapy.core.engine] INFO: Spider closed (finished)
2019-07-01 12:17:35 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: project)
2019-07-01 12:17:35 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.7.0, Python 3.6.3 |Anaconda, Inc.| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-7-6.1.7601-SP1
2019-07-01 12:17:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'project', 'LOG_FILE': 'meiju100.log', 'NEWSPIDER_MODULE': 'project.spiders', 'SPIDER_MODULES': ['project.spiders'], 'USER_AGENT': 'project (+http://www.yourdomain.com)'}
2019-07-01 12:17:35 [scrapy.extensions.telnet] INFO: Telnet Password: f8d73f039643002f
2019-07-01 12:17:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-07-01 12:17:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-07-01 12:17:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-07-01 12:17:36 [scrapy.middleware] INFO: Enabled item pipelines:
['project.pipelines.ProjectPipeline']
2019-07-01 12:17:36 [scrapy.core.engine] INFO: Spider opened
2019-07-01 12:17:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-07-01 12:17:36 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-07-01 12:17:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.meijutt.com/new100.html> (referer: None)
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '1',
 'name': '落跑公主第一季',
 's_type': '喜剧,剧情',
 'state': '第5集',
 'tv': 'My-Lifetime',
 'u_time': '2019-7-1'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '2',
 'name': '私家侦探第三季',
 's_type': '罪案,动作,剧情',
 'state': '第6集',
 'tv': 'Global',
 'u_time': '2019-7-1'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '3',
 'name': '德州长子第二季',
 's_type': '西部,剧情',
 'state': '第10集',
 'tv': 'AMC',
 'u_time': '2019-7-1'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '4',
 'name': '女子无畏第三季',
 's_type': '剧情',
 'state': '本季终',
 'tv': 'FREEFORM',
 'u_time': '2019-7-1'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '5',
 'name': '三色堇第一季',
 's_type': '罪案,剧情',
 'state': '第12集',
 'tv': '其他',
 'u_time': '2019-7-1'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '6',
 'name': '碰撞第一季',
 's_type': '惊悚,动作,剧情',
 'state': '第20集',
 'tv': 'Show-TV',
 'u_time': '2019-7-1'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '7',
 'name': '奇幻沼泽第一季',
 's_type': '喜剧,动画,冒险',
 'state': '第8集',
 'tv': 'Disney',
 'u_time': '2019-7-1'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '8',
 'name': '边境第三季',
 's_type': '冒险',
 'state': '第2集',
 'tv': 'Netflix',
 'u_time': '2019-7-1'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '9',
 'name': '血疫第一季',
 's_type': '惊悚,剧情',
 'state': '本季终',
 'tv': 'National-Geographic-Channel',
 'u_time': '2019-7-1'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '10',
 'name': '诡媚海妖第二季',
 's_type': '奇幻,剧情',
 'state': '第12集',
 'tv': 'FREEFORM',
 'u_time': '2019-7-1'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '11',
 'name': '处女情缘第五季',
 's_type': '喜剧,剧情',
 'state': '第13集',
 'tv': 'CW',
 'u_time': '2019-6-30'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '12',
 'name': '魔女之家第二季',
 's_type': '情景喜剧',
 'state': '第2集',
 'tv': 'Disney',
 'u_time': '2019-6-30'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '13',
 'name': '小丑梦摇篮第四季',
 's_type': '喜剧,剧情',
 'state': '第3集',
 'tv': 'FX',
 'u_time': '2019-6-30'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '14',
 'name': '天佑吾王第一季',
 's_type': '剧情',
 'state': '第43集',
 'tv': '其他',
 'u_time': '2019-6-30'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '15',
 'name': '太空终界第二季',
 's_type': '科幻,动画',
 'state': '第1集',
 'tv': '其他',
 'u_time': '2019-6-30'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '16',
 'name': '周六夜现场第四十四季',
 's_type': '真人秀',
 'state': '第21集',
 'tv': 'NBC',
 'u_time': '2019-6-30'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '17',
 'name': '毒品第一季',
 's_type': '记录',
 'state': '本季终',
 'tv': 'Netflix',
 'u_time': '2019-6-30'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '18',
 'name': '女飞贼杰特第一季',
 's_type': '罪案,动作',
 'state': '第3集',
 'tv': 'Cinemax',
 'u_time': '2019-6-30'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '19',
 'name': '游戏玩家第一季',
 's_type': '罪案,悬疑,动作,剧情',
 'state': '第4集',
 'tv': '其他',
 'u_time': '2019-6-30'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '20',
 'name': '归去第一季',
 's_type': '惊悚,悬疑',
 'state': '第3集',
 'tv': '其他',
 'u_time': '2019-6-30'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '21',
 'name': '天选之子第一季',
 's_type': '惊悚,悬疑',
 'state': '第5集',
 'tv': 'Netflix',
 'u_time': '2019-6-30'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '22',
 'name': '无限恩典有限公司第一季',
 's_type': '剧情',
 'state': '第4集',
 'tv': 'EPIX',
 'u_time': '2019-6-29'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '23',
 'name': '沼泽怪物第一季',
 's_type': '惊悚,奇幻',
 'state': '第5集',
 'tv': 'DC-Universe',
 'u_time': '2019-6-29'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '24',
 'name': '为人师表第一季',
 's_type': '喜剧',
 'state': '本季终',
 'tv': 'Netflix',
 'u_time': '2019-6-29'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '25',
 'name': '复仇者集结第二季',
 's_type': '动画',
 'state': '本季终',
 'tv': 'Disney',
 'u_time': '2019-6-29'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '26',
 'name': '菜鸟警察第六季',
 's_type': '罪案,剧情',
 'state': '全剧完结',
 'tv': 'ABC',
 'u_time': '2019-6-29'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '27',
 'name': '神盾局特工第六季',
 's_type': '科幻,动作',
 'state': '第7集',
 'tv': 'ABC',
 'u_time': '2019-6-29'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '28',
 'name': '图塔卡门第一季',
 's_type': '迷你剧,历史,剧情',
 'state': '全剧完结',
 'tv': 'ITV',
 'u_time': '2019-6-29'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '29',
 'name': '音乐玩家第三季',
 's_type': '青春,喜剧',
 'state': '第11集',
 'tv': 'Disney-Channel',
 'u_time': '2019-6-29'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '30',
 'name': '我是僵尸第五季',
 's_type': '罪案,惊悚,剧情,丧尸',
 'state': '第9集',
 'tv': 'CW',
 'u_time': '2019-6-29'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '31',
 'name': '暗中第一季',
 's_type': '罪案,剧情',
 'state': '本季终',
 'tv': 'CW',
 'u_time': '2019-6-29'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '32',
 'name': '福尔摩斯：基本演绎法第七季',
 's_type': '罪案,悬疑,剧情',
 'state': '第6集',
 'tv': 'CBS',
 'u_time': '2019-6-29'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '33',
 'name': '戴上手套擦泪第一季',
 's_type': '爱情,同性,动作',
 'state': '第3集',
 'tv': '其他',
 'u_time': '2019-6-29'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '34',
 'name': '神秘天使第二季',
 's_type': '悬疑,剧情,传记',
 'state': '第3集',
 'tv': 'CBS',
 'u_time': '2019-6-28'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '35',
 'name': '暗礁第一季',
 's_type': '罪案,悬疑',
 'state': '第2集',
 'tv': 'ABC',
 'u_time': '2019-6-28'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '36',
 'name': '主厨秀第一季',
 's_type': '真人秀',
 'state': '第8集',
 'tv': '其他',
 'u_time': '2019-6-28'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '37',
 'name': '女作家与谋杀案第七季',
 's_type': '罪案,悬疑,剧情',
 'state': '第9集',
 'tv': '其他',
 'u_time': '2019-6-28'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '38',
 'name': '少年泰坦出击第五季',
 's_type': '动画',
 'state': '第38集',
 'tv': 'Cartoon-Network',
 'u_time': '2019-6-28'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '39',
 'name': '赎金第三季',
 's_type': '罪案,剧情',
 'state': '第5集',
 'tv': 'CBS',
 'u_time': '2019-6-28'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '40',
 'name': '德雷尔一家第四季',
 's_type': '爱情,喜剧,剧情,传记',
 'state': '第6集',
 'tv': 'ITV',
 'u_time': '2019-6-28'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '41',
 'name': '南方女王第四季',
 's_type': '罪案,惊悚,动作,剧情',
 'state': '第4集',
 'tv': 'USA-Network',
 'u_time': '2019-6-28'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '42',
 'name': '生活点滴第四季',
 's_type': '喜剧',
 'state': '全剧完结',
 'tv': 'CBS',
 'u_time': '2019-6-28'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '43',
 'name': '黑白恋曲第一季',
 's_type': '爱情,暴力',
 'state': '第12集',
 'tv': '其他',
 'u_time': '2019-6-28'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '44',
 'name': '野兽家族第四季',
 's_type': '罪案,剧情',
 'state': '第5集',
 'tv': 'TNT',
 'u_time': '2019-6-28'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '45',
 'name': '戴面纱的美人第一季',
 's_type': '爱情,家庭,剧情',
 'state': '第8集',
 'tv': 'RAI-1',
 'u_time': '2019-6-28'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '46',
 'name': '海湾之谜第一季',
 's_type': '剧情',
 'state': '本季终',
 'tv': 'ITV',
 'u_time': '2019-6-28'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '47',
 'name': '氪星第二季',
 's_type': '科幻,动作,剧情,冒险',
 'state': '第3集',
 'tv': 'Syfy',
 'u_time': '2019-6-27'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '48',
 'name': '黄石公园第二季',
 's_type': '西部,剧情',
 'state': '第2集',
 'tv': '其他',
 'u_time': '2019-6-27'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '49',
 'name': '年轻一代第六季',
 's_type': '爱情,喜剧',
 'state': '第3集',
 'tv': '其他',
 'u_time': '2019-6-27'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '50',
 'name': '白粉飞第二季',
 's_type': '罪案,剧情',
 'state': '第6集',
 'tv': '其他',
 'u_time': '2019-6-27'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '51',
 'name': '糟糕历史第六季',
 's_type': '家庭,喜剧,历史',
 'state': '第9集',
 'tv': 'BBC',
 'u_time': '2019-6-27'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '52',
 'name': '极速前进第三十一季',
 's_type': '真人秀',
 'state': '第11集',
 'tv': 'CBS',
 'u_time': '2019-6-27'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '53',
 'name': '厨艺大师第十季',
 's_type': '真人秀',
 'state': '第6集',
 'tv': 'FOX',
 'u_time': '2019-6-27'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '54',
 'name': '蔗糖女王第四季',
 's_type': '剧情',
 'state': '第3集',
 'tv': 'Oprah-Winfre',
 'u_time': '2019-6-27'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '55',
 'name': '成长不容易第二季',
 's_type': '喜剧',
 'state': '第15集',
 'tv': 'FREEFORM',
 'u_time': '2019-6-27'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '56',
 'name': '姿态第二季',
 's_type': '歌舞,历史,剧情',
 'state': '第3集',
 'tv': 'FX',
 'u_time': '2019-6-27'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '57',
 'name': '变形金刚：领袖之证第一季',
 's_type': '动画',
 'state': '第8集',
 'tv': 'The-Hub',
 'u_time': '2019-6-27'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '58',
 'name': '真我人生第二季',
 's_type': '剧情',
 'state': '本季终',
 'tv': 'Starz',
 'u_time': '2019-6-27'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '59',
 'name': '血宝藏第一季',
 's_type': '罪案,悬疑,冒险',
 'state': '第7集',
 'tv': 'CBS',
 'u_time': '2019-6-27'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '60',
 'name': '侍女的故事第三季',
 's_type': '科幻,剧情',
 'state': '第6集',
 'tv': 'Hulu',
 'u_time': '2019-6-27'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '61',
 'name': '地球百子第六季',
 's_type': '科幻,悬疑,剧情',
 'state': '第8集',
 'tv': 'CW',
 'u_time': '2019-6-27'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '62',
 'name': '麻烦一家人第二季',
 's_type': '爱情,喜剧,剧情',
 'state': '第2集',
 'tv': 'FREEFORM',
 'u_time': '2019-6-26'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '63',
 'name': '一路绕行第四季',
 's_type': '喜剧',
 'state': '第2集',
 'tv': 'TBS',
 'u_time': '2019-6-26'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '64',
 'name': '三人行第四季',
 's_type': '喜剧,剧情',
 'state': '第5集',
 'tv': '其他',
 'u_time': '2019-6-26'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '65',
 'name': '疯狂教授生物课第二季',
 's_type': '喜剧',
 'state': '第12集',
 'tv': 'NBC',
 'u_time': '2019-6-26'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '66',
 'name': '本能第二季',
 's_type': '罪案,剧情',
 'state': '预告',
 'tv': 'CBS',
 'u_time': '2019-6-26'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '67',
 'name': '行星第一季',
 's_type': '记录',
 'state': '本季终',
 'tv': 'BBC',
 'u_time': '2019-6-26'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '68',
 'name': '怪探拉比特第一季',
 's_type': '悬疑,喜剧',
 'state': '第3集',
 'tv': 'Channel 4',
 'u_time': '2019-6-26'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '69',
 'name': '比彻姆大宅第一季',
 's_type': '剧情',
 'state': '第2集',
 'tv': 'ITV',
 'u_time': '2019-6-26'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '70',
 'name': '追寻人生第二季',
 's_type': '都市,剧情',
 'state': '第8集',
 'tv': 'ABC-Family',
 'u_time': '2019-6-26'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '71',
 'name': '大群第三季',
 's_type': '科幻,动作,剧情',
 'state': '第1集',
 'tv': 'FX',
 'u_time': '2019-6-26'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '72',
 'name': '浮华饭店第一季',
 's_type': '剧情',
 'state': '第2集',
 'tv': '其他',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '73',
 'name': '死亡医生玛丽第三季',
 's_type': '罪案,医务,剧情',
 'state': '本季终',
 'tv': 'Lifetime',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '74',
 'name': '前哨第二季',
 's_type': '科幻,奇幻,冒险',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '75',
 'name': '大小谎言第二季',
 's_type': '罪案,喜剧,剧情',
 'state': '第3集',
 'tv': 'HBO',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '76',
 'name': '王冠第三季',
 's_type': '历史,剧情',
 'state': '预告',
 'tv': 'Netflix',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '77',
 'name': '女子监狱第七季',
 's_type': '罪案,喜剧,剧情',
 'state': '预告',
 'tv': 'Netflix',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '78',
 'name': '绿箭侠第八季',
 's_type': '罪案,科幻,动作',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '79',
 'name': '豪门恩怨第三季',
 's_type': '罪案,剧情',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '80',
 'name': '新圣女魔咒第二季',
 's_type': '奇幻,剧情',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '81',
 'name': '吸血鬼后裔第二季',
 's_type': '魔幻,悬疑,奇幻',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '82',
 'name': '河谷镇第四季',
 's_type': '惊悚,悬疑,剧情',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '83',
 'name': '神探南茜第一季',
 's_type': '罪案,惊悚,悬疑',
 'state': '预告',
 'tv': '其他',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '84',
 'name': '邪恶力量第十五季',
 's_type': '魔幻,惊悚,悬疑',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '85',
 'name': '闪电侠第六季',
 's_type': '科幻,动作,冒险',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '86',
 'name': '蝙蝠女侠第一季',
 's_type': '科幻,动作,冒险',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '87',
 'name': '女超人第五季',
 's_type': '科幻,动作,冒险',
 'state': '预告',
 'tv': 'CW',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '88',
 'name': '安迪・麦克第三季',
 's_type': '青春,剧情',
 'state': '第3集',
 'tv': 'Disney',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '89',
 'name': '亢奋第一季',
 's_type': '罪案,剧情',
 'state': '第2集',
 'tv': 'HBO',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '90',
 'name': '西班牙公主第一季',
 's_type': '历史,剧情',
 'state': '本季终',
 'tv': 'Starz',
 'u_time': '2019-6-25'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '91',
 'name': '洛城战警第一季',
 's_type': '罪案,喜剧,动作',
 'state': '第11集',
 'tv': '其他',
 'u_time': '2019-6-24'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '92',
 'name': '燃呀马德里第一季',
 's_type': '歌舞,喜剧',
 'state': '本季终',
 'tv': '其他',
 'u_time': '2019-6-24'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '93',
 'name': '神秘法医第二季',
 's_type': '罪案,医务',
 'state': '第7集',
 'tv': 'ABC',
 'u_time': '2019-6-24'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '94',
 'name': '行尸之惧第五季',
 's_type': '惊悚,丧尸',
 'state': '第4集',
 'tv': 'AMC',
 'u_time': '2019-6-24'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '95',
 'name': '认罪口供第一季',
 's_type': '记录,罪案',
 'state': '第4集',
 'tv': 'Netflix',
 'u_time': '2019-6-24'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '96',
 'name': '另一面第一季',
 's_type': '惊悚,历史,剧情',
 'state': '第10集',
 'tv': 'RTVE',
 'u_time': '2019-6-24'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '97',
 'name': '黑暗物质三部曲第一季',
 's_type': '魔幻,奇幻',
 'state': '预告',
 'tv': 'BBC',
 'u_time': '2019-6-24'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '98',
 'name': '以人民之名第二季',
 's_type': '剧情',
 'state': '第9集',
 'tv': 'ABC',
 'u_time': '2019-6-24'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '99',
 'name': '美爪屋第三季',
 's_type': '喜剧',
 'state': '第3集',
 'tv': 'TNT',
 'u_time': '2019-6-24'}
2019-07-01 12:17:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.meijutt.com/new100.html>
{'index': '100',
 'name': '山巅之城第一季',
 's_type': '罪案,惊悚,剧情',
 'state': '第2集',
 'tv': 'Showtime',
 'u_time': '2019-6-24'}
2019-07-01 12:17:36 [scrapy.core.engine] INFO: Closing spider (finished)
2019-07-01 12:17:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 227,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6780,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 7, 1, 4, 17, 36, 600121),
 'item_scraped_count': 100,
 'log_count/DEBUG': 101,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 7, 1, 4, 17, 36, 60091)}
2019-07-01 12:17:36 [scrapy.core.engine] INFO: Spider closed (finished)
2019-07-01 12:18:43 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: project)
2019-07-01 12:18:43 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.7.0, Python 3.6.3 |Anaconda, Inc.| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-7-6.1.7601-SP1
2019-07-01 12:18:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'project', 'LOG_FILE': 'meiju100.log', 'NEWSPIDER_MODULE': 'project.spiders', 'SPIDER_MODULES': ['project.spiders'], 'USER_AGENT': 'project (+http://www.yourdomain.com)'}
2019-07-01 12:18:43 [scrapy.extensions.telnet] INFO: Telnet Password: 1f8700cf48713fb5
2019-07-01 12:18:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-07-01 12:18:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-07-01 12:18:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-07-01 12:18:43 [scrapy.middleware] INFO: Enabled item pipelines:
['project.pipelines.ProjectPipeline']
2019-07-01 12:18:43 [scrapy.core.engine] INFO: Spider opened
2019-07-01 12:18:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-07-01 12:18:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-07-01 12:18:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.meijutt.com/new100.html> (referer: None)
2019-07-01 12:18:43 [scrapy.core.engine] INFO: Closing spider (finished)
2019-07-01 12:18:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 227,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6780,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 7, 1, 4, 18, 43, 823966),
 'log_count/DEBUG': 1,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 7, 1, 4, 18, 43, 443945)}
2019-07-01 12:18:43 [scrapy.core.engine] INFO: Spider closed (finished)
2019-07-01 12:19:57 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: project)
2019-07-01 12:19:57 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.7.0, Python 3.6.3 |Anaconda, Inc.| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-7-6.1.7601-SP1
2019-07-01 12:19:57 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'project', 'LOG_FILE': 'meiju100.log', 'NEWSPIDER_MODULE': 'project.spiders', 'SPIDER_MODULES': ['project.spiders'], 'USER_AGENT': 'project (+http://www.yourdomain.com)'}
2019-07-01 12:19:57 [scrapy.extensions.telnet] INFO: Telnet Password: 051797bb76059b36
2019-07-01 12:19:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-07-01 12:19:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-07-01 12:19:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-07-01 12:19:57 [scrapy.middleware] INFO: Enabled item pipelines:
['project.pipelines.ProjectPipeline']
2019-07-01 12:19:57 [scrapy.core.engine] INFO: Spider opened
2019-07-01 12:19:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-07-01 12:19:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-07-01 12:19:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.meijutt.com/new100.html> (referer: None)
2019-07-01 12:19:57 [scrapy.core.engine] INFO: Closing spider (finished)
2019-07-01 12:19:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 227,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6780,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 7, 1, 4, 19, 57, 810198),
 'log_count/DEBUG': 1,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 7, 1, 4, 19, 57, 439177)}
2019-07-01 12:19:57 [scrapy.core.engine] INFO: Spider closed (finished)
2019-07-01 12:20:54 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: project)
2019-07-01 12:20:54 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.7.0, Python 3.6.3 |Anaconda, Inc.| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-7-6.1.7601-SP1
2019-07-01 12:20:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'project', 'LOG_FILE': 'meiju100.log', 'NEWSPIDER_MODULE': 'project.spiders', 'SPIDER_MODULES': ['project.spiders'], 'USER_AGENT': 'project (+http://www.yourdomain.com)'}
2019-07-01 12:20:54 [scrapy.extensions.telnet] INFO: Telnet Password: 90cfcd5e5205bc92
2019-07-01 12:20:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-07-01 12:20:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-07-01 12:20:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-07-01 12:20:54 [scrapy.middleware] INFO: Enabled item pipelines:
['project.pipelines.ProjectPipeline']
2019-07-01 12:20:54 [scrapy.core.engine] INFO: Spider opened
2019-07-01 12:20:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-07-01 12:20:54 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-07-01 12:20:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.meijutt.com/new100.html> (referer: None)
2019-07-01 12:20:54 [scrapy.core.engine] INFO: Closing spider (finished)
2019-07-01 12:20:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 227,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6780,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 7, 1, 4, 20, 54, 646449),
 'log_count/DEBUG': 1,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 7, 1, 4, 20, 54, 274428)}
2019-07-01 12:20:54 [scrapy.core.engine] INFO: Spider closed (finished)
2019-07-01 15:51:51 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: project)
2019-07-01 15:51:51 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.7.0, Python 3.6.3 |Anaconda, Inc.| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-7-6.1.7601-SP1
2019-07-01 15:51:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'project', 'LOG_FILE': 'meiju100.log', 'NEWSPIDER_MODULE': 'project.spiders', 'SPIDER_MODULES': ['project.spiders'], 'USER_AGENT': 'project (+http://www.yourdomain.com)'}
2019-07-01 15:51:51 [scrapy.extensions.telnet] INFO: Telnet Password: efc1167f6cdffb6a
2019-07-01 15:51:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-07-01 15:51:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-07-01 15:51:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-07-01 15:51:52 [scrapy.middleware] INFO: Enabled item pipelines:
['project.pipelines.ProjectPipeline']
2019-07-01 15:51:52 [scrapy.core.engine] INFO: Spider opened
2019-07-01 15:51:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-07-01 15:51:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-07-01 15:51:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.meijutt.com/new100.html> (referer: None)
2019-07-01 15:51:52 [scrapy.core.engine] INFO: Closing spider (finished)
2019-07-01 15:51:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 227,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6778,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 7, 1, 7, 51, 52, 583442),
 'log_count/DEBUG': 1,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 7, 1, 7, 51, 52, 145417)}
2019-07-01 15:51:52 [scrapy.core.engine] INFO: Spider closed (finished)
2019-07-01 15:58:57 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: project)
2019-07-01 15:58:57 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.7.0, Python 3.6.3 |Anaconda, Inc.| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-7-6.1.7601-SP1
2019-07-01 15:58:57 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'project', 'LOG_FILE': 'meiju100.log', 'NEWSPIDER_MODULE': 'project.spiders', 'SPIDER_MODULES': ['project.spiders'], 'USER_AGENT': 'project (+http://www.yourdomain.com)'}
2019-07-01 15:58:57 [scrapy.extensions.telnet] INFO: Telnet Password: 787bca1c67db0eda
2019-07-01 15:58:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-07-01 15:58:57 [twisted] CRITICAL: Unhandled error in Deferred:
2019-07-01 15:58:57 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "e:\anaconda\lib\site-packages\scrapy\utils\misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'project.mymiddlewares' has no attribute 'ProjectDownloaderMiddleware'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "e:\anaconda\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "e:\anaconda\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "e:\anaconda\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "e:\anaconda\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "e:\anaconda\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "e:\anaconda\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "e:\anaconda\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "e:\anaconda\lib\site-packages\scrapy\utils\misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'project.mymiddlewares' doesn't define any object named 'ProjectDownloaderMiddleware'
2019-07-01 16:00:27 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: project)
2019-07-01 16:00:27 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.7.0, Python 3.6.3 |Anaconda, Inc.| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-7-6.1.7601-SP1
2019-07-01 16:00:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'project', 'LOG_FILE': 'meiju100.log', 'NEWSPIDER_MODULE': 'project.spiders', 'SPIDER_MODULES': ['project.spiders'], 'USER_AGENT': 'project (+http://www.yourdomain.com)'}
2019-07-01 16:00:27 [scrapy.extensions.telnet] INFO: Telnet Password: 968ba06c6488353b
2019-07-01 16:00:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-07-01 16:00:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'project.mymiddlewares.ProxyMiddlerware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-07-01 16:00:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-07-01 16:00:27 [scrapy.middleware] INFO: Enabled item pipelines:
['project.pipelines.ProjectPipeline']
2019-07-01 16:00:27 [scrapy.core.engine] INFO: Spider opened
2019-07-01 16:00:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-07-01 16:00:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-07-01 16:00:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.meijutt.com/new100.html> (referer: None)
2019-07-01 16:00:28 [scrapy.core.engine] INFO: Closing spider (finished)
2019-07-01 16:00:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 227,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6809,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 7, 1, 8, 0, 28, 607957),
 'log_count/DEBUG': 1,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 7, 1, 8, 0, 27, 721906)}
2019-07-01 16:00:28 [scrapy.core.engine] INFO: Spider closed (finished)
2019-07-01 16:01:18 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: project)
2019-07-01 16:01:18 [scrapy.utils.log] INFO: Versions: lxml 4.1.0.0, libxml2 2.9.4, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.7.0, Python 3.6.3 |Anaconda, Inc.| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.2.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-7-6.1.7601-SP1
2019-07-01 16:01:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'project', 'LOG_FILE': 'meiju100.log', 'NEWSPIDER_MODULE': 'project.spiders', 'SPIDER_MODULES': ['project.spiders'], 'USER_AGENT': 'project (+http://www.yourdomain.com)'}
2019-07-01 16:01:18 [scrapy.extensions.telnet] INFO: Telnet Password: aca2b89d1d86ebdb
2019-07-01 16:01:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-07-01 16:01:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'project.mymiddlewares.ProxyMiddlerware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-07-01 16:01:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-07-01 16:01:18 [scrapy.middleware] INFO: Enabled item pipelines:
['project.pipelines.ProjectPipeline']
2019-07-01 16:01:18 [scrapy.core.engine] INFO: Spider opened
2019-07-01 16:01:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-07-01 16:01:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-07-01 16:01:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.meijutt.com/new100.html> (referer: None)
2019-07-01 16:01:19 [scrapy.core.engine] INFO: Closing spider (finished)
2019-07-01 16:01:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 227,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6809,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 7, 1, 8, 1, 19, 354859),
 'log_count/DEBUG': 1,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 7, 1, 8, 1, 18, 980838)}
2019-07-01 16:01:19 [scrapy.core.engine] INFO: Spider closed (finished)
